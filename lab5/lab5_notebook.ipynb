{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ed942f2",
   "metadata": {},
   "source": [
    "# Lab 5 - Apache Spark Word Frequency Analysis\n",
    "\n",
    "This notebook implements three tasks for word frequency analysis using Apache Spark:\n",
    "\n",
    "1. **Task 1**: Filter words starting with \"ho\" and compute statistics\n",
    "2. **Task 2**: Filter most frequent words (freq > 0.8 * maxfreq) and save them\n",
    "3. **Task 3**: Compute frequency distribution in groups\n",
    "\n",
    "**Input**: File with format `word\\tfreq` (word tab frequency)\n",
    "**Output**: Statistics and output files with results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a086f72",
   "metadata": {},
   "source": [
    "## Import libraries and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be28119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from pyspark import SparkConf, SparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa0b5e5",
   "metadata": {},
   "source": [
    "## Parameters configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc62b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration of paths and parameters\n",
    "inputPath = \"SampleLocalFile.csv\"  # For local environment\n",
    "# inputPath = \"/data/students/bigdata-01QYD/Lab2/\"  # For HDFS environment\n",
    "outputPath = \"res_out_Lab5/\" \n",
    "outputPath2 = \"res_out_Lab5_Task3/\"\n",
    "prefix = \"ho\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b9d62d",
   "metadata": {},
   "source": [
    "## Reading input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02247cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read input file\n",
    "wordsFrequenciesRDD = sc.textFile(inputPath)\n",
    "\n",
    "# Cache RDD to improve performance\n",
    "wordsFrequenciesRDD.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cde9f0",
   "metadata": {},
   "source": [
    "## Task 1: Filter words starting with \"ho\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3d4f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter lines containing words that start with prefix \"ho\"\n",
    "selectedLinesRDD = wordsFrequenciesRDD.filter(lambda line: line.startswith(prefix))\n",
    "\n",
    "# Cache for multiple usage\n",
    "selectedLinesRDD.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713a7b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of selected lines\n",
    "numLines = selectedLinesRDD.count()\n",
    "print(f\"Number of selected lines (words starting with '{prefix}'): {numLines}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8478c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate maximum frequency among selected lines\n",
    "if numLines > 0:\n",
    "    # Extract frequencies from selected lines\n",
    "    maxfreqRDD = selectedLinesRDD.map(lambda line: float(line.split(\"\\t\")[1]))\n",
    "    \n",
    "    # Calculate maximum value\n",
    "    maxfreq = maxfreqRDD.reduce(lambda freq1, freq2: max(freq1, freq2))\n",
    "    \n",
    "    print(f\"Maximum frequency among selected lines: {maxfreq}\")\n",
    "    \n",
    "else:\n",
    "    maxfreq = 0\n",
    "    print(f\"No words found starting with '{prefix}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13af872",
   "metadata": {},
   "source": [
    "## Task 2: Filter most frequent words and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d582d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "if maxfreq > 0:\n",
    "    threshold = 0.8 * maxfreq\n",
    "    print(f\"Frequency threshold (0.8 * {maxfreq}): {threshold}\")\n",
    "    \n",
    "    # Filter lines with frequency > 0.8 * maxfreq\n",
    "    selectedLinesMaxFreqRDD = selectedLinesRDD.filter(\n",
    "        lambda line: float(line.split(\"\\t\")[1]) > threshold\n",
    "    )\n",
    "else:\n",
    "    print(\"Cannot calculate threshold (maxfreq = 0)\")\n",
    "    selectedLinesMaxFreqRDD = sc.emptyRDD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f298d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of selected lines\n",
    "numLinesMaxfreq = selectedLinesMaxFreqRDD.count()\n",
    "print(f\"Number of lines with freq > 0.8*maxfreq: {numLinesMaxfreq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3715569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if numLinesMaxfreq > 0:\n",
    "    # Select only words (first field)\n",
    "    selectedWordsRDD = selectedLinesMaxFreqRDD.map(lambda line: line.split(\"\\t\")[0])\n",
    "    \n",
    "else:\n",
    "    print(\"No words meet the frequency threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbf6824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save selected words to output folder\n",
    "if numLinesMaxfreq > 0:\n",
    "    try:\n",
    "        selectedWordsRDD.saveAsTextFile(outputPath)\n",
    "        print(f\"Words saved successfully to: {outputPath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving to {outputPath}: {e}\")\n",
    "else:\n",
    "    print(\"No words to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b790de",
   "metadata": {},
   "source": [
    "## Task 3: Frequency distribution in groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831ccfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_group(line: str) -> Tuple[str, int]:\n",
    "    \"\"\"\n",
    "    Determine group membership based on frequency:\n",
    "    - Group 0: [0, 100)\n",
    "    - Group 1: [100, 200)\n",
    "    - Group 2: [200, 300)\n",
    "    - Group 3: [300, 400)\n",
    "    - Group 4: [400, 500)\n",
    "    - Group 5: [500, +inf)\n",
    "    \"\"\"\n",
    "    fields = line.split('\\t')\n",
    "    freq = int(fields[1])\n",
    "    \n",
    "    if freq >= 500:\n",
    "        group = 5\n",
    "    else:\n",
    "        group = freq // 100\n",
    "    \n",
    "    return (f'Group{group}', 1)\n",
    "\n",
    "# Calculate RDD with pairs (group, 1)\n",
    "groupPairRDD = wordsFrequenciesRDD.map(compute_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a934c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use reduceByKey to sum all +1 in value part\n",
    "countPerGroupPairRDD = groupPairRDD.reduceByKey(lambda v1, v2: v1 + v2)\n",
    "\n",
    "# Sort by key (group)\n",
    "sortedCountPerGroupRDD = countPerGroupPairRDD.sortByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ff4e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save frequency distribution results\n",
    "try:\n",
    "    sortedCountPerGroupRDD.saveAsTextFile(outputPath2)\n",
    "    print(f\"\\nFrequency distribution saved to: {outputPath2}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving to {outputPath2}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
